{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "various helper functions\n",
    "'''\n",
    "\n",
    "# Fixed-size Ordinally Forgetting Encoding\n",
    "def encode_FOFE(onehot, alpha, maxlen):\n",
    "    enc = np.zeros((maxlen, 2 * 22))\n",
    "    enc[0, :22] = onehot[0] \n",
    "    enc[maxlen-1, 22:] = onehot[maxlen-1] \n",
    "    for i in range(1, maxlen):\n",
    "        enc[i, :22] = enc[i-1, :22] * alpha + onehot[i]\n",
    "        enc[maxlen-i-1, 22:] = enc[maxlen-i, 22:] * alpha + onehot[maxlen-i-1]\n",
    "    return enc\n",
    "\n",
    "# The custom accuracy metric used for this task\n",
    "def accuracy(y_true, y_pred):\n",
    "    y = tf.argmax(y_true, axis =- 1)\n",
    "    y_ = tf.argmax(y_pred, axis =- 1)\n",
    "    mask = tf.greater(y, 0)\n",
    "    return K.cast(K.equal(tf.boolean_mask(y, mask), tf.boolean_mask(y_, mask)), K.floatx())\n",
    "\n",
    "def to_seq(y):\n",
    "    seqs=[]\n",
    "    for i in range(len(y)):\n",
    "        seq_i=''\n",
    "        for j in range(len(y[i])):\n",
    "            seq_i += q8_list[np.argmax(y[i][j])]\n",
    "        seqs.append(seq_i)\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residue_list = ['A', 'C', 'E', 'D', 'G', 'F', 'I', 'H', 'K', 'M', 'L', 'N', 'Q', 'P', 'S', 'R', 'T', 'W', 'V', 'Y', 'X','NoSeq']\n",
    "q8_list = ['L', 'B', 'E', 'G', 'I', 'H', 'S', 'T','NoSeq']\n",
    "\n",
    "cb513filename = '../data/cb513.npy'\n",
    "cb6133filename = '../data/cb6133.npy'\n",
    "cb6133filteredfilename = '../data/cb6133filtered.npy'\n",
    "\n",
    "cb513 = np.load(cb513filename)\n",
    "cb6133 = np.load(cb6133filename)\n",
    "cb6133filtered = np.load(cb6133filteredfilename)\n",
    "\n",
    "print(cb513.shape)\n",
    "print(cb6133.shape)\n",
    "print(cb6133filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_teams = 4\n",
    "\n",
    "teams_fold_preds_df = pd.read_table('meta-features/ln2401_kat2193-ddl2133_ks3311-ps2958_jw3468-yw3169_yh3050.csv')\n",
    "teams_fold_preds = teams_fold_preds_df['id,expected']\n",
    "\n",
    "teams_cb6133_preds_df = pd.read_table('meta-features/cb6133test_ln2401_kat2193-ddl2133_ks3311-ps2958_jw3468-yw3169_yh3050.csv')\n",
    "teams_cb6133_preds = teams_cb6133_preds_df['id,expected']\n",
    "\n",
    "teams_cb513_preds_df = pd.read_table('meta-features/cb513test_ln2401_kat2193-ddl2133_ks3311-ps2958_jw3468-yw3169_yh3050.csv')\n",
    "teams_cb513_preds = teams_cb513_preds_df['id,expected']\n",
    "\n",
    "train_input_teams = np.zeros((len(teams_fold_preds), 700, num_teams * 9))\n",
    "for i in range(len(teams_fold_preds)):\n",
    "    preds = teams_fold_preds[i].split(',')[1:]\n",
    "    for j in range(700):\n",
    "        if j < len(preds):\n",
    "            for k in range(num_teams):\n",
    "                onehot_idx = k * 9 + q8_list.index(preds[j][k])\n",
    "                train_input_teams[i, j, onehot_idx] = 1\n",
    "        else:\n",
    "            for k in range(num_teams):\n",
    "                onehot_idx = k * 9 + 8\n",
    "                train_input_teams[i, j, onehot_idx] = 1\n",
    "\n",
    "cb6133_input_teams = np.zeros((len(teams_cb6133_preds), 700, num_teams * 9))\n",
    "for i in range(len(teams_cb6133_preds)):\n",
    "    preds = teams_cb6133_preds[i].split(',')[1:]\n",
    "    for j in range(700):\n",
    "        if j < len(preds):\n",
    "            for k in range(num_teams):\n",
    "                onehot_idx = k * 9 + q8_list.index(preds[j][k])\n",
    "                cb6133_input_teams[i, j, onehot_idx] = 1\n",
    "        else:\n",
    "            for k in range(num_teams):\n",
    "                onehot_idx = k * 9 + 8\n",
    "                cb6133_input_teams[i, j, onehot_idx] = 1\n",
    "                \n",
    "print(train_input_teams.shape)\n",
    "print(cb6133_input_teams.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_seq = 700 # maximum sequence length\n",
    "alpha = 0.5 # parameter for long range encoding\n",
    "\n",
    "# getting inputs\n",
    "input_seqs = cb6133.reshape(6133, 700, 57)\n",
    "\n",
    "train_input_seqs = input_seqs[0:5600]\n",
    "train_input_data = np.zeros((5600, 700, 46))\n",
    "train_input_data[:, :, :22] = train_input_seqs[:, :, :22]\n",
    "train_input_data[:, :, 22:24] = train_input_seqs[:, :, 31:33]\n",
    "train_input_data[:, :, 24:] = train_input_seqs[:, :, 35:]\n",
    "\n",
    "train_input_onehot = train_input_data[:,:,0:22]\n",
    "train_input_fofe = np.array(list(map(lambda x:encode_FOFE(x, alpha, maxlen_seq), \n",
    "                                     train_input_onehot)))\n",
    "\n",
    "train_input_data = np.concatenate((train_input_data, train_input_fofe, train_input_teams), axis=2)\n",
    "\n",
    "test_input_seqs = input_seqs[5605:5877]\n",
    "test_input_data = np.zeros((272, 700, 46))\n",
    "\n",
    "test_input_data[:,:,:22] = test_input_seqs[:,:, :22]\n",
    "test_input_data[:,:,22:24] = test_input_seqs[:,:, 31:33]\n",
    "test_input_data[:,:,24:] = test_input_seqs[:,:, 35:]\n",
    "\n",
    "test_input_onehot = test_input_data[:,:,0:22]\n",
    "test_input_fofe = np.array(list(map(lambda x:encode_FOFE(x, alpha, maxlen_seq), \n",
    "                                     test_input_onehot)))\n",
    "\n",
    "test_input_data = np.concatenate((test_input_data, test_input_fofe, cb6133_input_teams), axis=2)\n",
    "\n",
    "# ... and targets\n",
    "train_target_data = train_input_seqs[:,:,22:31]\n",
    "test_target_data = test_input_seqs[:, :, 22:31]\n",
    "\n",
    "# Computing the number of words and number of tags \n",
    "n_words = len(train_input_data[0,0])\n",
    "n_tags = len(train_target_data[0,0])\n",
    "\n",
    "print(n_words, n_tags)\n",
    "print(train_input_data.shape, train_target_data.shape, test_input_data.shape, test_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(maxlen_seq, n_words,))\n",
    "\n",
    "# one dense layer to remove sparsity\n",
    "x = GaussianNoise(.75)(input)\n",
    "x = Dense(128, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(x)\n",
    "x = Reshape([maxlen_seq, 128, 1])(x)\n",
    "\n",
    "# Defining 3 convolutional layers with different kernel sizes\n",
    "# kernel size = 3\n",
    "conv1 = ZeroPadding2D((3//2, 0), data_format='channels_last')(x)\n",
    "conv1 = Conv2D(filters=64, \n",
    "               kernel_size=(3, 128), \n",
    "               input_shape=(1, maxlen_seq, 128), \n",
    "               data_format='channels_last',\n",
    "               strides=(1, 1), \n",
    "               dilation_rate=(1, 1), \n",
    "               activation='relu', \n",
    "               use_bias=True, \n",
    "               kernel_initializer='glorot_uniform', \n",
    "               bias_initializer='zeros')(conv1)\n",
    "conv1 = BatchNormalization(axis=-1)(conv1)\n",
    "\n",
    "# kernel size = 7\n",
    "conv2 = ZeroPadding2D((7//2, 0), data_format='channels_last')(x)\n",
    "conv2 = Conv2D(filters=64, \n",
    "               kernel_size=(7, 128), \n",
    "               input_shape=(1, maxlen_seq, 128), \n",
    "               data_format='channels_last',\n",
    "               strides=(1, 1), \n",
    "               padding='valid', \n",
    "               dilation_rate=(1, 1), \n",
    "               activation='relu', \n",
    "               use_bias=True, \n",
    "               kernel_initializer='glorot_uniform', \n",
    "               bias_initializer='zeros')(conv2)\n",
    "conv2 = BatchNormalization(axis=-1)(conv2)\n",
    "\n",
    "# kernel size = 11\n",
    "conv3 = ZeroPadding2D((11//2, 0), data_format='channels_last')(x)\n",
    "conv3 = Conv2D(filters=64, \n",
    "               kernel_size=(11, 128), \n",
    "               input_shape=(1, maxlen_seq, 128), \n",
    "               data_format='channels_last',\n",
    "               strides=(1, 1), \n",
    "               padding='valid', \n",
    "               dilation_rate=(1, 1), \n",
    "               activation='relu', \n",
    "               use_bias=True, \n",
    "               kernel_initializer='glorot_uniform', \n",
    "               bias_initializer='zeros')(conv3)\n",
    "conv3 = BatchNormalization(axis=-1)(conv3)\n",
    "conv = concatenate([conv1, conv2, conv3])\n",
    "conv = Reshape([maxlen_seq, 3*64])(conv)\n",
    "conv = GaussianNoise(.25)(conv)\n",
    "# conv = Reshape([maxlen_seq, 64])(conv2)\n",
    "# conv = GaussianNoise(7.5e-1)(conv)\n",
    "\n",
    "# Defining 3 bidirectional GRU layers; taking the concatenation of outputs \n",
    "gru1 = Bidirectional(GRU(32, \n",
    "                         return_sequences='True',\n",
    "                         activation='tanh', \n",
    "                         recurrent_activation='hard_sigmoid', \n",
    "                         use_bias=True, \n",
    "                         kernel_initializer='glorot_uniform', \n",
    "                         recurrent_initializer='orthogonal', \n",
    "                         bias_initializer='zeros', \n",
    "                         dropout=0.0,\n",
    "                         recurrent_dropout=0.5, \n",
    "                         implementation=1))(conv)\n",
    "# gru1 = GaussianNoise(7.5e-1)(gru1)\n",
    "\n",
    "gru2 = Bidirectional(GRU(32, \n",
    "                         return_sequences='True',\n",
    "                         activation='tanh', \n",
    "                         recurrent_activation='hard_sigmoid', \n",
    "                         use_bias=True, \n",
    "                         kernel_initializer='glorot_uniform', \n",
    "                         recurrent_initializer='orthogonal', \n",
    "                         bias_initializer='zeros', \n",
    "                         dropout=0.0,\n",
    "                         recurrent_dropout=0.5, \n",
    "                         implementation=1))(gru1)\n",
    "\n",
    "gru3 = Bidirectional(GRU(32, \n",
    "                         return_sequences='True',\n",
    "                         activation='tanh', \n",
    "                         recurrent_activation='hard_sigmoid', \n",
    "                         use_bias=True, \n",
    "                         kernel_initializer='glorot_uniform', \n",
    "                         recurrent_initializer='orthogonal', \n",
    "                         bias_initializer='zeros', \n",
    "                         dropout=0.0,\n",
    "                         recurrent_dropout=0.5, \n",
    "                         implementation=1))(gru2)\n",
    "\n",
    "comb = concatenate([gru1, gru2, gru3, conv])\n",
    "comb = GaussianNoise(.25)(comb)\n",
    "\n",
    "\n",
    "# Defining two fully-connected layers with dropout\n",
    "x = TimeDistributed(Dense(256, \n",
    "                          activation='relu', \n",
    "                          use_bias=True, \n",
    "                          kernel_initializer='glorot_uniform', \n",
    "                          bias_initializer='zeros'))(comb)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = TimeDistributed(Dense(128, \n",
    "                          activation='relu', \n",
    "                          use_bias=True,  \n",
    "                          kernel_initializer='glorot_uniform', \n",
    "                          bias_initializer='zeros'))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Defining the output layer\n",
    "y = TimeDistributed(Dense(n_tags, \n",
    "                          activation='softmax', \n",
    "                          use_bias=False, \n",
    "                          kernel_initializer='glorot_uniform'))(x)\n",
    "\n",
    "# Defining the model as a whole and printing the summary\n",
    "model = Model(input, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\", accuracy])\n",
    "model.fit(train_input_data, train_target_data, \n",
    "          batch_size = 64, epochs = 10, \n",
    "          validation_data = (test_input_data, test_target_data), \n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = model.predict(test_input_data[:])\n",
    "q8_structures = to_seq(y_)\n",
    "\n",
    "path = 'predictions/cb6133test_stacker_model5_4.csv'\n",
    "file_output = pd.DataFrame({'id' : np.array(range(272))+1, 'expected' : q8_structures}, columns=['id', 'expected'])\n",
    "file_output.to_csv(path, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
